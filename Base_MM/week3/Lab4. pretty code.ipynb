{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Untitled4.ipynb의 사본",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "uRVlZq75JUJn",
        "outputId": "81cc458b-e276-4c46-a253-d5fab304f0f0"
      },
      "source": [
        "!pip install -q torch==1.0.0 torchvision\n",
        "import torch\n",
        "print(torch.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tcmalloc: large alloc 1073750016 bytes == 0x61a42000 @  0x7f3777ea72a4 0x591a07 0x5b5d56 0x502e9a 0x506859 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x504c28 0x502540 0x502f3d 0x507641\n",
            "1.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PD4cIKKvKFCC"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import argparse\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29UainWPco7Y"
      },
      "source": [
        "## Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "Cu753dPPKGkV",
        "outputId": "43b9be12-27a2-48ac-d9d4-08ea5dab0658"
      },
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainset, valset = torch.utils.data.random_split(trainset, [40000, 10000])\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "valloader = torch.utils.data.DataLoader(valset, batch_size=4, \n",
        "                                        shuffle=False)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RxnfFJwBcsAv"
      },
      "source": [
        "## Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_G6bZbbkMWWt"
      },
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self, in_dim, out_dim, hid_dim, n_layer, act):\n",
        "        super(MLP, self).__init__()\n",
        "        self.in_dim = in_dim\n",
        "        self.out_dim = out_dim\n",
        "        self.hid_dim = hid_dim\n",
        "        self.n_layer = n_layer\n",
        "        self.act = act\n",
        "        \n",
        "        self.fc = nn.Linear(self.in_dim, self.hid_dim)\n",
        "        self.linears = nn.ModuleList()\n",
        "        \n",
        "        for i in range(self.n_layer-1):\n",
        "            self.linears.append(nn.Linear(self.hid_dim, self.hid_dim))\n",
        "        self.fc2 = nn.Linear(self.hid_dim, self.out_dim)\n",
        "        \n",
        "        if self.act == 'relu':\n",
        "            self.act = nn.ReLU()\n",
        "          \n",
        "    def forward(self, x):\n",
        "        x = self.act(self.fc(x))\n",
        "        for fc in self.linears:\n",
        "            x = self.act(fc(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "      \n",
        "net = MLP(3072, 10, 100, 4, 'relu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itGsp6jDWs_a"
      },
      "source": [
        "## Define Experiment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LiOCP6TqWw2V"
      },
      "source": [
        "def experiment(args):\n",
        "  \n",
        "    net = MLP(args.in_dim, args.out_dim, args.hid_dim, args.n_layer, args.act)\n",
        "    net.cuda()\n",
        "    print(net)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(net.parameters(), lr=args.lr, momentum=args.mm)\n",
        "    \n",
        "    for epoch in range(args.epoch):  # loop over the dataset multiple times\n",
        "\n",
        "        # ==== Train ===== #\n",
        "        net.train()\n",
        "        \n",
        "        running_loss = 0.0\n",
        "        train_loss = 0.0\n",
        "        for i, data in enumerate(trainloader, 0):\n",
        "            optimizer.zero_grad() # [21.01.05 오류 수정] 매 Epoch 마다 .zero_grad()가 실행되는 것을 매 iteration 마다 실행되도록 수정했습니다. \n",
        "\n",
        "            # get the inputs\n",
        "            inputs, labels = data\n",
        "            inputs = inputs.view(-1, 3072)\n",
        "            \n",
        "            inputs = inputs.cuda()\n",
        "            labels = labels.cuda()\n",
        "\n",
        "            # forward + backward + optimize\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # print statistics\n",
        "            running_loss += loss.item()\n",
        "            train_loss += loss.item()\n",
        "            if i % 2000 == 1999:    # print every 2000 mini-batches\n",
        "                print('[%d, %5d] loss: %.3f' %\n",
        "                      (epoch + 1, i + 1, running_loss / 2000))\n",
        "                running_loss = 0.0\n",
        "                \n",
        "\n",
        "        # ==== Validation ====== #\n",
        "        net.eval()\n",
        "        # optimizer.zero_grad() [21.01.05 코드 클린업] 아래 torch.no_grad()가 호출되고 Validation 과정에서는 Optimizer를 사용하지 않으므로 굳이 호출될 필요가 없습니다. \n",
        "        \n",
        "        correct = 0\n",
        "        total = 0\n",
        "        val_loss = 0 \n",
        "        with torch.no_grad():\n",
        "            for data in valloader:\n",
        "                images, labels = data\n",
        "                images = images.view(-1, 3072)\n",
        "                \n",
        "                images = images.cuda()\n",
        "                labels = labels.cuda()\n",
        "                \n",
        "                outputs = net(images)\n",
        "\n",
        "                loss = criterion(outputs, labels)\n",
        "                val_loss += loss.item()\n",
        "\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "            val_loss = val_loss / len(valloader)\n",
        "            val_acc = 100 * correct / total\n",
        "            \n",
        "        print('Epoch {}, Train Loss: {}, Val Loss: {}, Val Acc: {}'.format(epoch, train_loss, val_loss, val_acc ))\n",
        "\n",
        "\n",
        "    # ===== Evaluation ===== #\n",
        "    net.eval()\n",
        "    # optimizer.zero_grad() [21.01.05 코드 클린업] 아래 torch.no_grad()가 호출되고 Evaluation 과정에서는 Optimizer를 사용하지 않으므로 굳이 호출될 필요가 없습니다. \n",
        "    \n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data in testloader:\n",
        "            images, labels = data\n",
        "            images = images.view(-1, 3072)\n",
        "            images = images.cuda()\n",
        "            labels = labels.cuda()\n",
        "\n",
        "            outputs = net(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "        test_acc = 100 * correct / total\n",
        "            \n",
        "    return train_loss, val_loss, val_acc, test_acc\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omgExzmQgU1J"
      },
      "source": [
        "## Experiment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DRoOy_B3Wu7B"
      },
      "source": [
        "seed = 123\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "args = parser.parse_args(\"\")\n",
        "\n",
        "\n",
        "args.n_layer = 5\n",
        "args.in_dim = 3072\n",
        "args.out_dim = 10\n",
        "args.hid_dim = 100\n",
        "args.act = 'relu'\n",
        "\n",
        "args.lr = 0.001\n",
        "args.mm = 0.9\n",
        "args.epoch = 2\n",
        "\n",
        "\n",
        "list_var1 = [4, 5, 6]\n",
        "list_var2 = [50, 100, 150]\n",
        "\n",
        "for var1 in list_var1:\n",
        "    for var2 in list_var2:\n",
        "        args.n_layer = var1\n",
        "        args.hid_dim = var2\n",
        "        result = experiment(args)\n",
        "        print(result)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}